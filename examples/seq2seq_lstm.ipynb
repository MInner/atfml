{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport atfml\n",
    "%aimport atfml.bundles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# https://cs.stanford.edu/people/karpathy/char-rnn/warpeace_input.txt\n",
    "def build_leo_tolstoy_dataset(path='/home/usman/data/char_lstm/warpeace_input.txt', \n",
    "                              n_data = 10000, window=10, batch_size=100):\n",
    "    with open(path) as file:\n",
    "        string = (''.join([next(file) for x in range(n_data)]))[1:].replace('\\n', ' ')\n",
    "    charset = list(zip(*Counter(string).most_common(70)))[0]\n",
    "    ch_idx = lambda ch: charset.index(ch) + 1 if ch in charset else 0\n",
    "    X_list, y_list = [], []\n",
    "    for substr, target_char in [(string[i:i+window], string[i+window]) for i in range(n_data)]:\n",
    "        x_row = [ch_idx(char) for char in substr]\n",
    "        y = ch_idx(target_char)\n",
    "        X_list.append(x_row)\n",
    "        y_list.append(y)\n",
    "    n_batches = int(n_data/batch_size)\n",
    "    X = np.array(X_list)[:n_batches*batch_size]\n",
    "    y = np.array(y_list)[:n_batches*batch_size]\n",
    "    \n",
    "    return ([{'X': X_batch, 'y': y_batch} \n",
    "            for X_batch, y_batch \n",
    "            in zip(np.split(X, n_batches, axis=0), \n",
    "                   np.split(y, n_batches, axis=0))], \n",
    "            \n",
    "            {'charset_size': len(charset), \n",
    "             'mapping': dict(zip(charset, range(len(charset)))),\n",
    "             'back_mapping': dict(zip(range(len(charset)), charset))}\n",
    "           )\n",
    "\n",
    "def prediction_into_string(pred, data_spec, err = '#'):\n",
    "    if err in data_spec['mapping'].keys():\n",
    "        raise ValueError('Wow, change err, it should not be in the mapping')\n",
    "    \n",
    "    bm = data_spec['back_mapping']\n",
    "    return ''.join([(bm[n-1] if n > 0 else err) for n in pred.tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../bundles/lstm_decoder.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../bundles/lstm_decoder.py\n",
    "\n",
    "# defined in atfml/examples/Char_LSTM.ipynb\n",
    "from atfml.core import UnitBundle\n",
    "from atfml.utils import inits\n",
    "\n",
    "from atfml.bundles.lstm_encoder import LSTMEncoder\n",
    "\n",
    "class LSTMDecoder(UnitBundle):\n",
    "    def __init__(self, bk, name, n_hidden_dim, n_input_dim, n_steps, output_to_input_connection=True):\n",
    "        self.n_steps = n_steps\n",
    "        self.n_hidden_dim = n_hidden_dim\n",
    "        self.o_to_i = output_to_input_connection\n",
    "        \n",
    "        w_width = n_input_dim + n_hidden_dim\n",
    "        arg_dict = {\n",
    "            'name': name,\n",
    "            'weight_template': {\n",
    "                'x_0': {'shape': (n_input_dim, ) },\n",
    "                'c_0': {'shape': (n_hidden_dim, ) },\n",
    "                'W_i': {'shape': (w_width, n_hidden_dim), 'init_method': inits.identity_repeat_init },\n",
    "                'b_i': {'shape': (n_hidden_dim, ) },\n",
    "                'W_c': {'shape': (w_width, n_hidden_dim), 'init_method': inits.identity_repeat_init },\n",
    "                'b_c': {'shape': (n_hidden_dim, ) },\n",
    "                'W_f': {'shape': (w_width, n_hidden_dim), 'init_method': inits.identity_repeat_init },\n",
    "                'b_f': {'shape': (n_hidden_dim, ) },\n",
    "                'W_o': {'shape': (w_width, n_hidden_dim), 'init_method': inits.identity_repeat_init },\n",
    "                'b_o': {'shape': (n_hidden_dim, ) },\n",
    "                'V_c': {'shape': (n_hidden_dim, n_hidden_dim), \n",
    "                        'init_method': inits.identity_repeat_init },\n",
    "            },\n",
    "            'data_template': {\n",
    "                'X_expected': ('batch_size', self.n_steps, n_input_dim),\n",
    "                'H_0': ('batch_size', n_hidden_dim),\n",
    "            }\n",
    "        }\n",
    "        super().__init__(bk, **arg_dict)\n",
    "        \n",
    "    def _func(self, theta, data, const):\n",
    "        \"\"\" same as LSTM as in LSTMBundle \"\"\"\n",
    "        np = None\n",
    "        bk = self.bk\n",
    "        h_prev = data.H_0\n",
    "        c_prev = bk.repeat(theta.c_0[bk.newaxis, :], const.batch_size, axis=0)\n",
    "        X_0 = bk.repeat(theta.x_0[bk.newaxis, :], const.batch_size, axis=0)\n",
    "        if self.o_to_i:\n",
    "            X_effective = bk.concatenate([X_0[:, bk.newaxis, :], data.X_expected[:, :-1, :]], axis=1)\n",
    "        else:\n",
    "            X_effective = bk.repeat(X_0[:, bk.newaxis, :], self.n_steps, axis=1)\n",
    "      \n",
    "        decoded_list = []\n",
    "        sigmoid = lambda x: x/(1+bk.abs(x+1e-20))\n",
    "        for t in range(self.n_steps):\n",
    "            x_t = X_effective[:, t, :]\n",
    "            concat_h_x = bk.concatenate([h_prev, x_t], axis=1)\n",
    "            i_t = sigmoid(bk.dot(concat_h_x, theta.W_i) + theta.b_i[bk.newaxis, :])\n",
    "            c_tld_t = sigmoid(bk.dot(concat_h_x, theta.W_c) + theta.b_c[bk.newaxis, :])\n",
    "            f_t = sigmoid(bk.dot(concat_h_x, theta.W_f) + theta.b_f[bk.newaxis, :])\n",
    "            c_t = bk.multiply(i_t, c_tld_t) + bk.multiply(f_t, c_prev)\n",
    "            o_t = sigmoid(bk.dot(concat_h_x, theta.W_o) + bk.dot(c_t, theta.V_c) \n",
    "                          + theta.b_o[bk.newaxis, :])\n",
    "            h_t = bk.multiply(o_t, bk.tanh(c_t))\n",
    "            h_prev = h_t\n",
    "            c_prev = c_t\n",
    "            \n",
    "            decoded_list.append(h_prev)\n",
    "            \n",
    "        decoded = bk.concatenate([x[:, bk.newaxis, :] for x in decoded_list], axis=1)\n",
    "        bk.assert_arr_shape({decoded.shape: (const.batch_size, self.n_steps, self.n_hidden_dim)})\n",
    "        \n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight shapes are: {'decoder__b_i': (100,), 'decoder__c_0': (100,), 'decoder__x_0': (100,), 'encoder__W_c': (200, 100), 'encoder__b_f': (100,), 'decoder__W_i': (200, 100), 'encoder__V_c': (100, 100), 'encoder__W_o': (200, 100), 'encoder__b_c': (100,), 'decoder__W_o': (200, 100), 'decoder__W_f': (200, 100), 'encoder__W_f': (200, 100), 'encoder__c_0': (100,), 'E': (70, 100), 'decoder__b_c': (100,), 'encoder__b_i': (100,), 'encoder__W_i': (200, 100), 'decoder__V_c': (100, 100), 'decoder__b_f': (100,), 'decoder__W_c': (200, 100), 'encoder__h_0': (100,), 'encoder__b_o': (100,), 'decoder__b_o': (100,)}, n_total_params: 188200\n",
      "FAST_COMPILE\n",
      "Building learning step function and gradient .... done\n",
      "Building  score.. done\n",
      "Building  predict.. done\n",
      "Building  loss.. done\n",
      "Charset:  70\n",
      "0  1.535e+04     0.1707\n",
      ">>  warn you, if you don't tell m | hc'PPotot ,t' tot t''oEhthsd,t\n",
      "50       8470      0.245\n",
      ">>  believe a word that Hardenbur |  huclllerEnwhto thet hene rdes\n",
      "100       7161      0.388\n",
      ">> But I warn you, if you don't t | eur t aa eetou  an you din't t\n",
      "150       7407     0.3137\n",
      ">> ord that Hardenburg says, or H |  n ethet uevoerdurs,wons  an o\n",
      "200       6981     0.3647\n",
      ">> and Lucca are now just family  |     tomhhnm e tot Iol  toteld \n",
      "250       7064      0.356\n",
      ">> m.... And I don't believe a wo |  e ...End w hon't he ilverEnso\n",
      "300       6587     0.3933\n",
      ">> I warn you, if you don't tell  |   ces atou  Is you win't foai \n",
      "350       6238     0.4473\n",
      ">> word that Hardenburg says, or  | ear  thet sev erdur  aois  af \n",
      "400       6064     0.4797\n",
      ">> re now just family estates of  |  e not Iust fotely axs le smf \n",
      "450       5923     0.4897\n",
      ">> z either. This famous Prussian |  etvther  Then Aociultarissta \n",
      "500       5686     0.5153\n",
      ">> d Lucca are now just family es | n tutaalmne mot Iust ootely.lx\n",
      "550       5609     0.5057\n",
      ">> hat Hardenburg says, or Haugwi |  ev weroerdur ,aais  an mesghi\n",
      "600       5283      0.552\n",
      ">> artes. But I warn you, if you  |  leeds Hut t cas. tou  bf you \n",
      "650       5348     0.5267\n",
      ">> believe a word that Hardenburg |  u ievertncaur thet weryerduri\n",
      "700       5174     0.5807\n",
      ">> the Buonapartes. But I warn yo | t e buonaparte s Hut t dass ao\n",
      "750       4880     0.5617\n",
      ">> rg says, or Haugwitz either. T | ra aoy   av weugwitt enther  T\n",
      "800       4754      0.621\n",
      ">> arn you, if you don't tell me  | ev  tou  bf you won't foll mem\n",
      "850       4587     0.6203\n",
      ">> ieve a word that Hardenburg sa | itdersnsord thet werderdurg,ta\n",
      "900       4465     0.6653\n",
      ">> Lucca are now just family esta | eacaatane now tust oatily.bxta\n",
      "950       4496     0.6097\n",
      ">> t Hardenburg says, or Haugwitz |   rar er urg,aai , ov maug itt\n",
      "1000       4275     0.6637\n",
      ">> ut I warn you, if you don't te |  n f cas, your af yourwon't lo\n",
      "1050       3850      0.671\n",
      ">> ord that Hardenburg says, or H | ou  that Harded urg,aais, on i\n",
      "1100       4186     0.6537\n",
      ">> ince, so Genoa and Lucca are n | etge  Io yelo  mnd Luccanane n\n",
      "1150       3666     0.6723\n",
      ">> a word that Hardenburg says, o |  vrord toet Berden urg wais, o\n",
      "1200       3784      0.687\n",
      ">> tes of the Buonapartes. But I  | thrsyf the wuonaparte . But y \n",
      "1250       3462      0.689\n",
      ">> , or Haugwitz either. This fam |   an waugwitz enther  Thes bom\n",
      "1300       3446      0.696\n",
      ">> a are now just family estates  |  twne dow aust family.avtati  \n",
      "1350       3302     0.7357\n",
      ">> . And I don't believe a word t |   Hnd w don't becieve s wird t\n",
      "1400       3421      0.736\n",
      ">>  of the Buonapartes. But I war | aIu the Duonapartes. But h war\n",
      "1450       3314     0.7443\n",
      ">> elieve a word that Hardenburg  | s feve t sord fhat wardenburg \n",
      "1500       3171     0.7503\n",
      ">> ily estates of the Buonapartes |  nl.avtati  bf the wuonaparte \n",
      "1550       3013     0.7613\n",
      ">> denburg says, or Haugwitz eith |   dturg uay , or ciugwitz eith\n",
      "1600       3091     0.7537\n",
      ">> f the Buonapartes. But I warn  |  oyhe huonaparte . But I ward \n",
      "1650       3085     0.7403\n",
      ">> ope is powerless before him... | hnedis cowerleds before him. .\n",
      "1700       2978     0.7857\n",
      ">> if you don't tell me that this |  sutourwon't tell me that whis\n",
      "1750       3057     0.7447\n",
      ">> ess before him.... And I don't |   s oecire him. .. And w con't\n",
      "1800       3034     0.7637\n",
      ">> st family estates of the Buona |  i aotily rvtat   af the wuona\n",
      "1850       2756     0.7733\n",
      ">> .. And I don't believe a word  | h .And w hon't believedi word \n",
      "1900       2741     0.7763\n",
      ">> and Lucca are now just family  |  t  toccanare now just aamily \n",
      "1950       2830     0.7717\n",
      ">> ys, or Haugwitz either. This f | e   an Haughitz either. Thas m\n",
      "2000       2593     0.8037\n",
      ">> uonapartes. But I warn you, if |  nneparte . But I warn you, if\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEACAYAAABPiSrXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niIjkpqAhIiK5KWiIiEhuChoiIpLb/wdr7cn8TWZrLwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3ceaf6fa20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from atfml.core import AutoGradBackend, TheanoBackend\n",
    "import atfml.utils as utils\n",
    "from atfml.utils import inits, behaviours as bhvs\n",
    "from atfml.bundles.lstm_encoder import LSTMEncoder\n",
    "from atfml.bundles.lstm_decoder import LSTMDecoder\n",
    "\n",
    "# bk = AutoGradBackend()\n",
    "bk = TheanoBackend()\n",
    "\n",
    "class Seq2SeqAutoencoder(bk.ModelLoss):\n",
    "    def __init__(self, *, vocab_size, n_hidden_dim, seq_len, data_spec):      \n",
    "        self.n_hidden_dim = n_hidden_dim\n",
    "        self.n_embedding_dim = n_hidden_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.seq_len = seq_len\n",
    "        self.data_spec = data_spec\n",
    "        \n",
    "        arg_dict = {\n",
    "            'data_template': {\n",
    "                'X': {'shape':('batch_size', self.seq_len), 'dtype': 'int64' },\n",
    "            },\n",
    "            'default_init_method': inits.gaussian_init_with(mu=0, std=1),\n",
    "            'weight_template': {\n",
    "                'E': {'shape':(self.vocab_size, self.n_embedding_dim) },\n",
    "            },\n",
    "            'weight_bundles': {\n",
    "                'encoder': {'class': LSTMEncoder, \n",
    "                            'args': {'n_hidden_dim':n_hidden_dim, \n",
    "                                     'n_input_dim': self.n_embedding_dim, \n",
    "                                     'n_steps': seq_len} },\n",
    "                'decoder': {'class': LSTMDecoder,\n",
    "                            'args': {'n_hidden_dim':n_hidden_dim, \n",
    "                                     'n_input_dim': self.n_embedding_dim, \n",
    "                                     'n_steps': seq_len,\n",
    "                                     'output_to_input_connection': True}},\n",
    "                \n",
    "            },\n",
    "            'optimization_method': {'name': 'adam', 'learning_rate': 0.005, 'clip': 100},\n",
    "            'behaviours': {\n",
    "                'loss': bhvs.LossLogBehaviour(),\n",
    "            }\n",
    "        }\n",
    "        super().__init__(**arg_dict)\n",
    "    \n",
    "    @bk.export\n",
    "    def predict(self, theta, data, const):\n",
    "        np = None # for safety\n",
    "        embedded_X = theta.E[data.X] # [batch_size, seq_len, n_hidden_him]\n",
    "        h_last = self.bundles.encoder.apply(theta, {'X':embedded_X}) # [batch_size, n_hidden_dim]\n",
    "        X_pred = self.bundles.decoder.apply(theta, {'X_expected': embedded_X, \n",
    "                                                    'H_0': h_last}) # as embedded_X\n",
    "        ## [batch_size, seq_len, n_hidden_dim] * [n_hidden, vocab_size]\n",
    "        ## -> [batch_size, seq_len, vocab_size]\n",
    "        output_seq_prob = bk.ops.softmax(bk.dot(X_pred, theta.E.T) )\n",
    "        bk.assert_arr_shape({output_seq_prob.shape: (const.batch_size, self.seq_len, self.vocab_size)})\n",
    "        return output_seq_prob\n",
    "    \n",
    "    def loss(self, theta, data, const):\n",
    "        np = None # for safety\n",
    "        output_seq_prob = self.raw.predict(theta, data, const)\n",
    "        ## output_seq_prob: [batch_size, seq_len, vocab_size], X: [batch_size, seq_len]\n",
    "        ## correct_probs: [batch_size, seq_len]\n",
    "        ii, jj = bk.indices((const.batch_size, self.seq_len))\n",
    "        correct_probs = output_seq_prob[ii, jj, data.X[ii, jj]]\n",
    "        loss = bk.sum( -bk.log( correct_probs ) )\n",
    "        return loss\n",
    "    \n",
    "    @bk.export\n",
    "    def score(self, theta, data, const):\n",
    "        np = None # for safety\n",
    "        output_prob = self.raw.predict(theta, data, const)\n",
    "        X_pred = bk.argmax(output_prob, axis=2)\n",
    "        score = bk.sum( bk.isclose(X_pred, data.X), dtype='float32')/const.batch_size/self.seq_len\n",
    "        return score\n",
    "    \n",
    "    def step_callback(self, loss_val, theta, data, const, info):\n",
    "        bk = None\n",
    "        if info['n_iter'] % 50 == 0:\n",
    "            score_val = self.compiled.score(theta, data, const)\n",
    "            print('%d %10.4g %10.4g' % (info['n_iter'], loss_val, score_val))\n",
    "            self.generate_output(theta, data, const, info)\n",
    "            \n",
    "    def generate_output(self, theta, data, const, info):\n",
    "        ## print random prediction as a string\n",
    "        i_to_check = np.random.randint(const.batch_size)\n",
    "        data_line = data.X[i_to_check].reshape((1, -1))\n",
    "        original_string = prediction_into_string(data_line.ravel(), self.data_spec)\n",
    "\n",
    "        small_data = utils.to_record({'X': data_line}) # we don't care about y\n",
    "        local_const = utils.to_record({'batch_size': 1}) # dirty stub :(\n",
    "        output_prob = self.compiled.predict(theta, small_data, local_const)\n",
    "        X_pred = np.argmax(output_prob, axis=2).ravel()\n",
    "\n",
    "        reconstructed_string = prediction_into_string(X_pred, self.data_spec)\n",
    "        print('>>', original_string, '|', reconstructed_string)\n",
    "\n",
    "def test_lstm_on_leo():\n",
    "    seq_len = 30\n",
    "    data, data_spec = build_leo_tolstoy_dataset(n_data = 10000, window=seq_len, batch_size=100)\n",
    "    model = Seq2SeqAutoencoder(n_hidden_dim=100, vocab_size=data_spec['charset_size'], \n",
    "                               seq_len=seq_len, data_spec=data_spec)\n",
    "    print('Charset: ', data_spec['charset_size'])\n",
    "    only_X_data = [{'X': data_i['X']} for data_i in data]\n",
    "    best_theta = model.fit(only_X_data, n_max_steps=2000)\n",
    "    plt.plot(model.behaviours.loss.log)\n",
    "    plt.show()\n",
    "    \n",
    "test_lstm_on_leo()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
